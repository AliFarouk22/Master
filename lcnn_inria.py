# -*- coding: utf-8 -*-
"""LCNN INRIA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vqypyev2yqCYs3ZqCXrjXTauHsk7N58b

# **Connect to Drive**
"""

import tensorflow as tf
from keras import layers, models, losses, activations, optimizers, metrics, regularizers, initializers, callbacks

print(tf.VERSION)
print(tf.keras.__version__)


# from keras import layers, models, losses, activations, optimizers, metrics, regularizers, initializers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
# import tensorflow as tf

np.random.seed(123)
tf.set_random_seed(123)

from google.colab import drive
drive.mount('/content/drive')

"""# **Imports**"""

import keras

from skimage import exposure
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

import numpy as np
# import tensorflow as tf
import random as rn
from keras import backend as K

from keras import models
from keras.utils import CustomObjectScope
from keras.initializers import glorot_uniform

from keras.applications import VGG16

from sklearn.model_selection import GridSearchCV
# from keras.models import Sequential
# from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
# from keras.optimizers import SGD

import cv2
import os
import shutil

from keras.utils import plot_model

from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from keras.models import Model, load_model
from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout
from keras.layers.core import Lambda, RepeatVector, Reshape
from keras.layers.convolutional import Conv2D, Conv2DTranspose, SeparableConv2D
from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D
from keras.layers.merge import concatenate, add
from keras.optimizers import Adam, RMSprop, Nadam
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras import losses
from keras.activations import relu
from keras.layers import advanced_activations

"""# ***Read full image 224 x 224***"""

# train_dir = '/content/drive/My Drive/Master/Dataset/INRIA/Train/train/' ## INRIA 
# train_dir = '/content/drive/My Drive/Master/Dataset/Stanford40_SomeClasses/' ## Stanford40 
# train_dir = '/content/drive/My Drive/Master/Dataset/ImageNet/train/' ## ImageNet 
train_dir = '/content/drive/My Drive/Master/Dataset/ImgNt_INR_Stan/' ## ALL datasets ImgNet_INR_Stan
# train_dir = '/content/drive/My Drive/Master/Dataset/ImgNt_INR_Sample/' ## ImgNt & INR Samples
validation_dir = '/content/drive/My Drive/Master/Dataset/INRIA/Train/validation/'

# width_shift_range=0.0,
# height_shift_range=0.0,
# brightness_range=None,
# shear_range=0.0,
# zoom_range=0.0,
# fill_mode='nearest',
# horizontal_flip=False,

transformationNumber = 3


def contrast_stretching(img):
#     print(np.max(img) , type(img[0][0][0]))
    p2, p98 = np.percentile(img, (2, 98))
    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98), out_range=(p2, p98))
#     img_rescale = exposure.equalize_adapthist(img_rescale/255., clip_limit=0.05)
#     img_rescale.astype(int)
    
    return img_rescale

# train_datagen = ImageDataGenerator(rescale=1./255, 
#                                    featurewise_center=True,
#                                    featurewise_std_normalization=True,
# #                                    preprocessing_function=contrast_stretching,
# #                                    zca_whitening=True
# #                                    width_shift_range=0.3, 
# #                                    height_shift_range=0.3,
# #                                    brightness_range=None,
# #                                    shear_range=0.3,
# #                                    zoom_range=0.3,
# #                                    fill_mode='nearest',
# #                                    horizontal_flip=True
#                                   )

datagen = ImageDataGenerator(rescale=1./255, 
#                              featurewise_center=True, 
#                              featurewise_std_normalization=True,
#                              width_shift_range=[-100, 100], 
#                              height_shift_range=[-100, 100],
                             preprocessing_function=contrast_stretching
)

batchTrain = 30
batchValidation = 30


train_generator = datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=batchTrain, class_mode='binary', shuffle=True, seed=1234)#, save_to_dir='G:\PyCharmWorkspace\Keras\\all\SavedFromKerasGenerator')
validation_generator = datagen.flow_from_directory(validation_dir, target_size=(224, 224), batch_size=batchValidation, class_mode='binary', seed=1234)
# test_generator = test_datagen.flow_from_directory(test_dir, target_size=(128, 64), batch_size=740, class_mode='binary')
# train_generator = train_datagen.flow(x=, batch_size=32, save_to_dir='')

print("Generator Sizes: ", train_generator.n, ", ", validation_generator.n)
print("Batch Sizes: ", train_generator.batch_size, ", ", validation_generator.batch_size)
print("Number of Classes: ", train_generator.num_classes, ", ", validation_generator.num_classes)
# print("classes: ", train_generator[0])
# print("classes: ", train_generator.shuffle)

print(train_generator[0][0].shape)
img = train_generator[0][0][10]
print("===================", np.max(img) , type(img[0][0][0]), img.mean())
plt.imshow(img)
plt.show()


"""# Code to make results ***reproducable***"""

# The below is necessary for starting Numpy generated random numbers
# in a well-defined initial state.

np.random.seed(42)

# The below is necessary for starting core Python generated random numbers
# in a well-defined state.

rn.seed(1234)

# Force TensorFlow to use single thread.
# Multiple threads are a potential source of non-reproducible results.
# For further details, see: https://stackoverflow.com/questions/42022950/

session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,
                              inter_op_parallelism_threads=1)


# The below tf.set_random_seed() will make random number generation
# in the TensorFlow backend have a well-defined initial state.
# For further details, see:
# https://www.tensorflow.org/api_docs/python/tf/set_random_seed

tf.set_random_seed(1234)

sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)
K.set_session(sess)

# Rest of code follows ...

"""# **Model**"""

dropout=0.35
mySeed = 1234
initializer = initializers.glorot_uniform(seed=mySeed)#truncated_normal(mean=0.0, stddev=0.5, seed=mySeed)#random_normal(mean=0.0, stddev=0.01, seed=mySeed)
l2Value = 0.001

model = models.Sequential()

# keras.layers.SeparableConv2D(filters,
#                              kernel_size,
#                              strides=(1, 1),
#                              padding='valid',
#                              data_format=None,
#                              dilation_rate=(1, 1),
#                              depth_multiplier=1,
#                              activation=None,
#                              use_bias=True,
#                              depthwise_initializer='glorot_uniform',
#                              pointwise_initializer='glorot_uniform',
#                              bias_initializer='zeros',
#                              depthwise_regularizer=None, 
#                              pointwise_regularizer=None,
#                              bias_regularizer=None, 
#                              activity_regularizer=None, 
#                              depthwise_constraint=None,
#                              pointwise_constraint=None, 
#                              bias_constraint=None)

# conv_1_512_11_s3_MP_DO_sep_2_128_9_s3_MP_DO_64_3_s1_MP_DO_RMS_003_L2_001_glorot.h5

model.add(layers.Conv2D(filters=64, kernel_size=(7, 7), #activation='relu',
                        input_shape=(224, 224, 3),
                        kernel_regularizer=regularizers.l2(l2Value),
                        strides=(1, 1), padding='same',
                        kernel_initializer=initializer
                       ))
model.add(layers.BatchNormalization(axis=3))
model.add(layers.Activation('relu'))
# model.add(layers.activations.relu())
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(dropout, seed=mySeed))

#bottleneck
# model.add(layers.Conv2D(filters=20, kernel_size=(1, 1),
#                         kernel_regularizer=regularizers.l2(l2Value),
#                         strides=(1, 1), padding='same',
#                         kernel_initializer=initializer
#                         ))
# model.add(layers.Activation('relu'))

model.add(layers.SeparableConv2D(filters=64, kernel_size=(5, 5),# activation='relu',
                                 strides=(1, 1),
                                 padding='same', data_format='channels_last', depth_multiplier=1,
                                 depthwise_regularizer=regularizers.l2(l2Value),
                                 pointwise_regularizer=regularizers.l2(l2Value),
                                 depthwise_initializer=initializer, 
                                 pointwise_initializer=initializer
                                ))
model.add(layers.BatchNormalization(axis=3))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(dropout, seed=mySeed))

#bottleneck
# model.add(layers.Conv2D(filters=16, kernel_size=(1, 1),
#                         kernel_regularizer=regularizers.l2(l2Value),
#                         strides=(1, 1), padding='same',
#                         kernel_initializer=initializer
#                         ))
# model.add(layers.Activation('relu'))

model.add(layers.SeparableConv2D(filters=128, kernel_size=(3, 3),# activation='relu',
                                 strides=(1, 1),
                                 padding='same', data_format='channels_last', depth_multiplier=1,
                                 depthwise_regularizer=regularizers.l2(l2Value),
                                 pointwise_regularizer=regularizers.l2(l2Value),
                                 depthwise_initializer=initializer, 
                                 pointwise_initializer=initializer
                                ))
model.add(layers.BatchNormalization(axis=3))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(dropout, seed=mySeed))

#bottleneck
# model.add(layers.Conv2D(filters=16, kernel_size=(1, 1),
#                         kernel_regularizer=regularizers.l2(l2Value),
#                         strides=(1, 1), padding='same',
#                         kernel_initializer=initializer
#                         ))
# model.add(layers.Activation('relu'))

model.add(layers.SeparableConv2D(filters=128, kernel_size=(3, 3),# activation='relu',
                                 strides=(1, 1),
                                 padding='same', data_format='channels_last', depth_multiplier=1,
                                 depthwise_regularizer=regularizers.l2(l2Value),
                                 pointwise_regularizer=regularizers.l2(l2Value),
                                 depthwise_initializer=initializer, 
                                 pointwise_initializer=initializer
                                ))
model.add(layers.BatchNormalization(axis=3))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(dropout, seed=mySeed))

#bottleneck
# model.add(layers.Conv2D(filters=32, kernel_size=(1, 1),
#                         kernel_regularizer=regularizers.l2(l2Value),
#                         strides=(1, 1), padding='same',
#                         kernel_initializer=initializer
#                         ))
# model.add(layers.Activation('relu'))

model.add(layers.SeparableConv2D(filters=512, kernel_size=(3, 3),# activation='relu',
                                 strides=(1, 1),
                                 padding='same', data_format='channels_last', depth_multiplier=1,
                                 depthwise_regularizer=regularizers.l2(l2Value),
                                 pointwise_regularizer=regularizers.l2(l2Value),
                                 depthwise_initializer=initializer, 
                                 pointwise_initializer=initializer
                                ))
model.add(layers.BatchNormalization(axis=3))
model.add(layers.Activation('relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(dropout, seed=mySeed))

#bottleneck
model.add(layers.Conv2D(filters=128, kernel_size=(1, 1),
                        kernel_regularizer=regularizers.l2(l2Value),
                        strides=(1, 1), padding='same',
                        kernel_initializer=initializer
                        ))
model.add(layers.Activation('relu'))

# 7*7 
model.add(layers.SeparableConv2D(filters=512, kernel_size=(7, 7),# activation='relu',
                                 strides=(1, 1),
                                 padding='valid', data_format='channels_last', depth_multiplier=1,
                                 depthwise_regularizer=regularizers.l2(l2Value),
                                 pointwise_regularizer=regularizers.l2(l2Value),
                                 depthwise_initializer=initializer, 
                                 pointwise_initializer=initializer
                                ))
model.add(layers.BatchNormalization(axis=3))
model.add(layers.Activation('relu'))
model.add(layers.Flatten())
# model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2Value) , kernel_initializer=initializer))
# model.add(layers.Dropout(dropout, seed=mySeed))
model.add(layers.Dense(1, activation='sigmoid', kernel_initializer=initializer))

print( model.summary() )


"""# **Compile Model**"""

model.compile(optimizer=optimizers.Adam(lr=0.0007),# decay=0.001),
#               optimizer=tf.train.RMSPropOptimizer(learning_rate=0.003),
              loss=losses.binary_crossentropy,
              metrics=[metrics.binary_accuracy]
             )


print( model.summary() )
# print( model.get_weights() )
# print( model.get_config() )

# model_saved = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/CNN_Models/temp.h5', compile=True)

# model.set_weights(model_saved.get_weights())


"""# **VGG layers weights to model**"""

conv_base = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(224, 224, 3))

conv_base.summary()

# with CustomObjectScope({'GlorotUniform': glorot_uniform()}):
#   model = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/LCNN_Models/conv_1_512_11_s3_MP_DO_sep_2_128_9_s3_MP_DO_64_3_s1_MP_DO_RMS_003_L2_001_glorot.h5', compile=True)

model.summary()

print('My Model weights: ', type(model.get_weights()), len(model.get_weights()))
print('VGG16 Model weights: ', type(conv_base.get_weights()), len(conv_base.get_weights()))

vggWeights = np.empty(0)

for vggLayer in conv_base.layers:

  if "conv" in vggLayer.name:
  
    vggModelLayerWeightsFlattened = vggLayer.get_weights()[0].flatten()
    print("Flattened VGG Weights Shape: ", vggModelLayerWeightsFlattened.shape, ", ", vggLayer.get_weights()[0].shape)
    vggWeights = np.concatenate((vggWeights, vggModelLayerWeightsFlattened), axis=None)
    
print("VGG weights flattened appended Length: ", vggWeights.shape)

# np.random.shuffle(vggWeights)


i = 0

for lay in model.layers:
  
  print(lay.name)
  lastStop = 0
  
  if "conv" in lay.name:
    
    vggWeightsToModelWeights = []
    numWeightsArraysInLayer = len(lay.get_weights())
    print("numWeightsArraysInLayer: ", numWeightsArraysInLayer)
    
    for j in range(numWeightsArraysInLayer):
      layerSize = lay.get_weights()[j].shape
      print("layerSize: ", layerSize)
      layerShapeMultiplied = 1
      
      for dim in layerSize:
        layerShapeMultiplied *= dim
      
      x = vggWeights[lastStop: (lastStop + layerShapeMultiplied)].reshape(layerSize)
      lastStop = lastStop + layerShapeMultiplied
      vggWeightsToModelWeights.append(x)
      
    print ("Sizes of vggWeightsToModelWeights: ", len(vggWeightsToModelWeights))
    for weights in vggWeightsToModelWeights:
      print(len(weights))
      
    model.layers[i].set_weights(vggWeightsToModelWeights)
    
  i += 1

"""# **Run Model**"""

# model.compile(optimizer=optimizers.RMSprop(lr=0.001),#, decay=0.0),
# #               optimizer=tf.train.RMSPropOptimizer(learning_rate=0.003),
#               loss=losses.binary_crossentropy,
#               metrics=[metrics.binary_accuracy]
#              )
# model = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/LCNN_Models/sequential_withContrastStandardization_ImageNet_Stanford_DO35_LR0007_L2001.h5')


print( model.summary() )
# print( model.get_weights() )
# print( model.get_config() )

# model_saved = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/CNN_Models/temp.h5', compile=True)

# model.set_weights(model_saved.get_weights())
callbacks = [
    # EarlyStopping(patience=3, verbose=1),
    ReduceLROnPlateau(factor=0.9, patience=10, min_lr=0.0001, verbose=1),
    # ReduceLROnPlateau(factor=0.01, patience=3, min_lr=0.0001, verbose=1),
    # ModelCheckpoint('/content/drive/Shared drives/Medical Images/Lungs/Bounding Box and Ground Truth V2/model-unet_Med_Lar_9Layers_2.h5', verbose=1, save_best_only=True)#, save_weights_only=True)
    ModelCheckpoint("/content/drive/My Drive/Master/INRIA_images_hog/MyIdea/my_keras_model_bottleneck_104.h5",
                    # /content/drive/My Drive/Master/INRIA_images_hog/MyIdea
                                          save_best_only=True)#, save_weights_only=True)
]
# checkpoint_cb = callbacks.ModelCheckpoint("/content/drive/My Drive/Master/INRIA_images_hog/MyIdea/my_keras_model_bottleneck_100.h5",
#                                           save_best_only=True)

history = model.fit_generator(train_generator,
                              steps_per_epoch=train_generator.n/batchTrain, #((train_generator.n * transformationNumber)/batch),
                              epochs=100,
                              validation_data=validation_generator,
                              validation_steps=(validation_generator.n/batchValidation), 
                              callbacks=callbacks)

# history = model.fit(train_x, train_y, batch_size=64, epochs=10)

acc = history.history['binary_accuracy']
val_acc = history.history['val_binary_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()


# train_generator_2 = test_datagen.flow_from_directory(validation_dir, target_size=(128, 64), batch_size=batch, class_mode='binary')

# history = model.fit_generator(train_generator_2,
#                               steps_per_epoch=(train_generator_2.n/batch),
#                               epochs=10)

# acc = history.history['binary_accuracy']
# loss = history.history['loss']

# print("classes: ", train_generator_2.classes)

# model.save('/content/drive/My Drive/Master/INRIA_images_hog/CNN_Models/temp.h5')

"""# Test"""

# with CustomObjectScope({'GlorotUniform': glorot_uniform()}):
# model = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/LCNN_Models/conv_1_512_11_s3_MP_DO_sep_2_128_9_s3_MP_DO_64_3_s1_MP_DO_RMS_003_L2_001_glorot.h5', compile=True)
# model = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/LCNN_Models/conv_1_32_11_s4_MP_DO_sep_2_16_9_s3_DO_16_3_s1_MP_DO_Dense_2_64_DO_16_DO_RMS_001_L2_001_glorot.h5', compile=True)
# model = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/LCNN_Models/temp93P86N_DO35_LR0007_L201.h5', compile=True)
# model = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/LCNN_Models/together_withContrast_Stride_1_DO35_LR0007_L2001.h5')
# model = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/MyIdea/my_keras_model_6.h5')
model = models.load_model('/content/drive/My Drive/Master/INRIA_images_hog/MyIdea/my_keras_model_bottleneck_103.h5')#my_keras_model_bottleneck_9.h5')

plot_model(model, to_file='/content/drive/My Drive/Master/INRIA_images_hog/CNN_Models/model.png')

# test_dir = '/content/drive/My Drive/Master/Dataset/INRIA/Test/test/'
test_dir_pos = '/content/drive/My Drive/Master/Dataset/INRIA/Test/test/pos/' #AllData/test/pos/'
test_dir_neg = '/content/drive/My Drive/Master/Dataset/INRIA/Test/test/neg/' #AllData/test/neg/'
# test_dir_pos = '/content/drive/My Drive/Master/Dataset/GeneratedTest/allImages/'#workingPos#allImages/' #AllData/test/pos/'
# test_dir_pos = '/content/drive/My Drive/Master/Dataset/GeneratedTest/Ali_and_Ahmed/'


test_generator_pos = datagen.flow_from_directory(test_dir_pos, target_size=(224, 224), batch_size=1, class_mode='binary', seed=1234)
print("classes: ", test_generator_pos.classes)
test_generator_neg = datagen.flow_from_directory(test_dir_neg, target_size=(224, 224), batch_size=1, class_mode='binary', seed=1234)
print("classes: ", test_generator_neg.classes)

pos11 = np.round( model.predict_generator(test_generator_pos, steps=test_generator_pos.n) )
pos1 = np.mean( np.round( model.predict_generator(test_generator_pos, steps=test_generator_pos.n) ) )
neg1 = 1 - np.mean( np.round( model.predict_generator(test_generator_neg, steps=test_generator_neg.n) ) )

# correctPredictionsIndixes = np.nonzero(pos11.reshape((1, -1)))[1]
# print("indexes: ", correctPredictionsIndixes, "\ntype: ", type(correctPredictionsIndixes))
# correctImagesNames = np.asarray(test_generator_pos.filenames)[correctPredictionsIndixes]
pos11 = np.reshape(pos11, newshape=(1, -1))
print("__________________________________ SHAPE: ", pos11.shape)
names = np.asarray(test_generator_pos.filenames)
for index in range(pos11.shape[1]):
  if pos11[0, index] == 1.0:
    imageName = names[index]
    print ("index: ", index, "     prediction: ", pos11[0, index], "     imageName: ", imageName)
    # imagePath = test_dir_pos + imageName
    # shutil.copy((imagePath) , ("/content/drive/My Drive/Master/Dataset/GeneratedTest/Ok3/" + imageName))
#     # copy( (imagePath) , ("/content/drive/My Drive/Master/Dataset/GeneratedTest/Ok/" + imageName) )Ali_and_Ahmed2




print( "pos: ", pos11, "\n", np.sum(pos11) ) 
print( "pos: ", pos1 ) 
print( "neg: ", neg1 )

print( "True pos: ", pos1 ) 
print( "True neg: ", neg1 )
print( "False pos:", 1 - neg1 )
print( "False neg:", 1 - pos1 )

# Accuracy = (TP+TN)/(TP+TN+FP+FN)
# â€¢	F-score = 2TP / (2TP + FP + FN)

totalAccuracy = (pos1 + neg1) / (pos1 + neg1 + (1-neg1) + (1-neg1))#(pos * (test_generator_pos.n/(test_generator_pos.n + test_generator_neg.n)) ) + (neg * (test_generator_neg.n/(test_generator_pos.n + test_generator_neg.n)) )
F_Score = (2*pos1) / ( (2*pos1) + (1-neg1) + (1-pos1) )
print("Total Accuracy: ", totalAccuracy, "F-Score", F_Score)



################################################


print ("#####-------------------- Test on ImageNet -------------------#####")
test_dir_pos_ImageNet = '/content/drive/My Drive/Master/Dataset/ImageNet/test/pos/' #AllData/test/pos/'
test_dir_neg_ImageNet = '/content/drive/My Drive/Master/Dataset/ImageNet/test/neg/' #AllData/test/neg/'

test_generator_pos = datagen.flow_from_directory(test_dir_pos_ImageNet, target_size=(224, 224), batch_size=1, class_mode='binary')
print("classes: ", test_generator_pos.classes)
test_generator_neg = datagen.flow_from_directory(test_dir_neg_ImageNet, target_size=(224, 224), batch_size=1, class_mode='binary')
print("classes: ", test_generator_neg.classes)


pos2 = np.mean( np.round( model.predict_generator(test_generator_pos, steps=test_generator_pos.n) ) )
neg2 = 1 - np.mean( np.round( model.predict_generator(test_generator_neg, steps=test_generator_neg.n) ) )


print( "pos: ", pos2 ) 
print( "neg: ", neg2 )

print( "True pos: ", pos2 ) 
print( "True neg: ", neg2 )
print( "False pos:", 1 - neg2 )
print( "False neg:", 1 - pos2 )


totalAccuracy = (pos2 + neg2) / (pos2 + neg2 + (1-neg2) + (1-neg2))#(pos * (test_generator_pos.n/(test_generator_pos.n + test_generator_neg.n)) ) + (neg * (test_generator_neg.n/(test_generator_pos.n + test_generator_neg.n)) )
F_Score = (2*pos2) / ( (2*pos2) + (1-neg2) + (1-pos2) )
print("Total Accuracy: ", totalAccuracy, "F-Score", F_Score)

# ##################################

print ("#####-------------------- Test on Pascal Voc 2007 -------------------#####")
test_dir_pos_ImageNet = '/content/drive/My Drive/Master/Dataset/PascalVoc2007/test/pos/' #AllData/test/pos/'
# test_dir_neg_ImageNet = '/content/drive/My Drive/Master/Dataset/ImageNet/test/neg/' #AllData/test/neg/'

test_generator_pos = datagen.flow_from_directory(test_dir_pos_ImageNet, target_size=(224, 224), batch_size=1, class_mode='binary')
print("classes: ", test_generator_pos.classes)
# test_generator_neg = datagen.flow_from_directory(test_dir_neg_ImageNet, target_size=(224, 224), batch_size=1, class_mode='binary')
# print("classes: ", test_generator_neg.classes)


pos3 = np.mean( np.round( model.predict_generator(test_generator_pos, steps=test_generator_pos.n) ) )
# neg = 1 - np.mean( np.round( model.predict_generator(test_generator_neg, steps=test_generator_neg.n) ) )


print( "pos: ", pos3 ) 
# print( "neg: ", neg )

print( "True pos: ", pos3 ) 
# print( "True neg: ", neg )
# print( "False pos:", 1 - neg )
print( "False neg:", 1 - pos3 )

# totalAccuracy = pos / test_generator_pos.n #(pos * (test_generator_pos.n/(test_generator_pos.n + test_generator_neg.n)) ) + (neg * (test_generator_neg.n/(test_generator_pos.n + test_generator_neg.n)) )

# F-Score = (2*pos) / ( (2*pos) + (1-neg) + (1-pos))
# print("Total Accuracy: ", totalAccuracy, "F-Score", F-Score)

print ("#####-------------------- Test on All Datasets -------------------#####")

totalPos = (pos1 + pos2 + pos3) / 3
totalNeg = (neg1 + neg2) / 2


print( "total pos: ", totalPos ) 
print( "total neg: ", totalNeg )

print( "True pos: ", totalPos ) 
print( "True neg: ", totalNeg )
print( "False pos:", 1 - totalNeg )
print( "False neg:", 1 - totalPos )


totalAccuracy = (totalPos + totalNeg) / (totalPos + totalNeg + (1-totalNeg) + (1-totalNeg))#(pos * (test_generator_pos.n/(test_generator_pos.n + test_generator_neg.n)) ) + (neg * (test_generator_neg.n/(test_generator_pos.n + test_generator_neg.n)) )
F_Score = (2*totalPos) / ( (2*totalPos) + (1-totalNeg) + (1-totalPos) )
print("Total Accuracy: ", totalAccuracy, "F-Score", F_Score)

